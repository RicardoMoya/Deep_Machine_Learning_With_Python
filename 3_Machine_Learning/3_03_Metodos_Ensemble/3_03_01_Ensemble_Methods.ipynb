{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 3.3.1- Ensemble Methods\n",
    "\n",
    "* En este Notebook vamos a ver que son los métodos ensemble y los tipos de métodos ensemble que hay:\n",
    "<span></span><br>\n",
    "    1. [Ensemble Methods](#M1)\n",
    "<span></span><br>\n",
    "    2. [Bagging](#M2)\n",
    "<span></span><br>\n",
    "    3. [Boosting](#M3)\n",
    "<span></span><br>\n",
    "    4. [Staking](#M4)\n",
    "    \n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "## <a name=\"M1\">1. Ensemble Methods</a>\n",
    "\n",
    "\n",
    "* Los ***Métodos Ensemble*** son un tipo de métodos que ***hacen uso de una o colección de modelos que se utilizan conjuntamente para realizar una predicción***.\n",
    "\n",
    "\n",
    "* Los métodos ensemble generan (usando uno o más algoritmos de aprendizaje) varios modelos; utilizando cada uno de ellos, un subconjunto de datos del Dataset.\n",
    "\n",
    "\n",
    "* A la hora de ***realizar las predicciones, cada uno de los modelos generados emitirá de manera independiente su predicción y en base a una determinada política se calculará la predicción final teniendo en cuenta las predicciones individuales de cada uno de los modelos***.\n",
    "\n",
    "\n",
    "* Estos métodos funcionan bastante bien debido a que hacen uso de varios modelos, de los cuales seguramente haya algunos que cometan errores altos en las predicciones, pero habra otros muchos que sean muy precisos y ***los altos errores cometidos por unos modelos serán compensados por los bajos errores cometidos por otros***.\n",
    "\n",
    "\n",
    "* Los métodos Ensemble no pueden ser considerados como Algoritmos de Aprendizaje ya que no generan un modelo si no que generan (con uno o varios Algoritmos de Aprendizaje) una colección de modelos con los que predecir; por tanto podemos decir, que los Métodos Ensemble lo que generan es un \"***Metamodelo***\".\n",
    "\n",
    "\n",
    "* En terminos de Bias-Variance los Métodos Ensemble ayudan a reducir la varianza (Variance) a demás de reducir considerablemente el sesgo (Bias) por la anulación del sesgo propio de los modelos individuales, lo que explica por qué un Ensemble puede ser mejor que cualquiera de los modelos individuales que lo componen.\n",
    "\n",
    "\n",
    "* Empiricamente los Métodos Ensemble obtienen mejores resultados cuando existe cierta diversidad en los modelos generados. Esta diversidad en los modelos la podemos introducir utilizando diferentes estrategias conocidas como Staking, Bagging y Boosting.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "## <a name=\"M2\">2. Bagging</a>\n",
    "\n",
    "\n",
    "* Este tipo de Método Ensemble ***utiliza*** (por lo general y no necesariamente) ***un mismo Algoritmo de Aprendizaje*** con el cual generará una ***colección de modelos*** entrenados de manera independiente.\n",
    "\n",
    "\n",
    "* Para construir los modelos del ensemble (con el Algoritmo de Aprendizaje pertinente) se utiliza ***Bootstrapping*** que es una ***técnica de selección de elementos*** del Dataset, el cual ***genera numerosas versiones de conjuntos de elementos a partir del Dataset de entrenamiento utilizando muestreo por remplazo***. Cada una de esas versiones de conjuntos de elementos se utilizará para construir un modelo diferente.\n",
    "\n",
    "\n",
    "* ***Para realizar una prediccion, los diferentes modelos del ensemble realizarán la prediccion por separado y la predicción final será***\n",
    "<span></span><br><br>\n",
    "    - Problemas de ***Clasificación***: ***Cada modelo realiza una predicción y la predicción final es la clase que más modelos han predicho***. Dicho de otra manera, cada modelo emite un vota para decidir a que clase pertenece un elemento y gana aquella clase que más votos tenga (mayoría simple).\n",
    "<span></span><br><br>\n",
    "    - Problemas de ***Regresión***: El ***valor medio de las predicciones ofrecidas por los modelos***.\n",
    "\n",
    "\n",
    "* En resumen, la ***predicción final será la moda (para problemas de clasificación) o la media (para problemas de regresión) de las predicciones de los modelos individuales***.\n",
    "\n",
    "\n",
    "* En la siguiente imagen mostramos un ejemplo del Bagging en el que se utiliza como Algoritmo de Aprendizaje un CART *\\[Classification And Regression Trees\\]* para la clasificación:\n",
    "\n",
    "\n",
    "<img src=\"../../imgs/3_03_01_02_em.jpg\" style=\"width: 700px;\"/>\n",
    "\n",
    "\n",
    "* Uno de los métodos Ensemble de Bagging más conocido es el \"***Random Forest***\" (descrito por Leo Breiman en 2001) que ***utiliza como Algoritmo de Aprendizaje los CART*** *\\[Classification And Regression Trees\\]*, ***entrenando cada uno de los modelos de manera independiente con diferentes conjuntos de datos, lo cual introduce cierta variedad en los modelos*** lo que nos permitirá obtener mejores resultados.\n",
    "\n",
    "\n",
    "* En terminos de *Bias-Variance*, el *Bias* (sesgo) del Random Forest es equivalente al de un Árbol de Decisión individual (bajo ya que los CART tienden al overfitting); sin embargo, creando muchos Árboles de Decisión (un bosque) y agregando sus predicciones el *Variance* (varianza) se reduce respecto al *Variance* de un Árbol de Decisión individual que tiende a tener un *Variance* alto.\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "## <a name=\"M3\">3. Boosting</a>\n",
    "\n",
    "\n",
    "* Este tipo de Método Ensemble ***utiliza un mismo Algoritmo de Aprendizaje*** para generar la colección de modelos ***usando el mismo Dataset de entrenamiento***.\n",
    "\n",
    "\n",
    "* Este tipo de Método Ensemble ***comienza generando un modelo \"base\"***. Una vez generado el modelo, ***calcula las predicciones*** para cada uno de los elementos del Dataset de entrenamiento y realiza las siguientes acciones:\n",
    "\n",
    "    1. Selecciona los ***elementos que ha clasificado de manera correcta***.\n",
    "    2. Selecciona los ***elementos que ha clasificado de manera incorrecta***.\n",
    "    3. ***Calcula la precisión del modelo***.\n",
    "    \n",
    "    \n",
    "* El siguiente paso es ***generar un segundo modelo, partiendo del primer modelo*** pero en este caso el segundo modelo ***lo genera dando un mayor peso a los elementos del dataset mal clasificados por el primer modelo***. De la misma manera que con el primer modelo, realiza las predicciones con los datos de entrenamiento, ***calculando la preción***  y ***clasificando los elementos del Dataset en función de si los clasifica de manera correcta o incorrecta***.\n",
    "\n",
    "\n",
    "* Este procedimiento se va repitiendo hasta llegar a una condición de parada como pueda ser por ejemplo la de crear 'N' modelos o la de obtener un error inferior a un determinado umbral en el último modelo.\n",
    "\n",
    "\n",
    "* El nombre de este Método Ensemble *Boosting* se puede traducir como \"***impulsar***\" ya que consiste en **generar un modelo inicial básico*** que clasifique algo mejor que un modelo aleatorio y posteriormente ***va generando nuevos modelos*** (partiendo del modelo anterior) que (en teoria) ***clasifican mejor que el modelo anterior hasta llegar a conseguir un modelo que clasifique de manera casi perfecta***.\n",
    "\n",
    "\n",
    "* A la hora de realizar una predicción, ***todos los modelos generados calcularán su predicción, siendo la predicción final la media ponderada (ponderada por la precisión) de las predicciones individuales de los modelos***; es decir, que la predicción del primer modelo generado tendrá un peso menor sobre la predicción final que la predicción ofrecida por el último modelo generado que será un modelo casi perfecto.\n",
    "\n",
    "\n",
    "* En la siguiente imagen podemos ver un ejemplo del funcionamiento del *Boosting*:\n",
    "\n",
    "<img src=\"../../imgs/3_03_01_03_em.jpg\" style=\"width: 700px;\"/>\n",
    "\n",
    "\n",
    "* La implementación más habitual del *Boosting* es el algoritmo del ***AdaBoost*** (Adaptative Boosting) que consiste en interpretar el *Boosting* como un proceso de optimización sobre una función de perdida (función de coste). El AdaBoost es un proceso de optimización particular del *Gradient Boosting*.\n",
    "\n",
    "\n",
    "* Dos de las librerías que implementan el Boosting son las librerías de ***XGBoost*** y ***LightGBM*** las cuales son muy populares en las competiciones de Kaggle ya que ofrecen resultados tan buenos que en muchas ocasiones los ganadores de los concursos utilizan estas librerías para emitir las predicciones.\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "## <a name=\"M4\">4. Staking</a>\n",
    "\n",
    "\n",
    "* Este tipo de Método Ensemble ***utiliza varios tipos de Algoritmos de Aprendizaje distintos*** para generar la colección de modelos.\n",
    "\n",
    "\n",
    "* Para ofrecer la ***predicción final, utiliza un Algoritmo de Aprendizaje que generará un modelo capaz de combinar las predicciones individuales de la colección de modelos***.\n",
    "\n",
    "\n",
    "* El Staking no solo admite cualquier tipo de Algoritmo de Aprendizaje para generar uno de los modelos de la colección, si no que también admite las técnicas de Ensembles *Bagging* y *Boosting* vistas anteriormente.\n",
    "\n",
    "\n",
    "* Los modelos individuales que forman la colección de modelos, pueden ser generados por los Algoritmos de Aprendizaje utilizando el mismo Dataset de entrenamiento.\n",
    "\n",
    "\n",
    "* En la siguiente imagen vemos un ejemplo gráfico del Stacking:\n",
    "\n",
    "\n",
    "<img src=\"../../imgs/3_03_01_01_em.jpg\" style=\"width: 700px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "Este Notebook ha sido desarrollado por **Ricardo Moya García** y registrado en Safe Creative como ***Atribución-NoComercial-CompartirIgual***.\n",
    "\n",
    "\n",
    "<img src=\"../../imgs/CC_BY-NC-SA.png\" alt=\"CC BY-NC\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1.6 - Regularización\n",
    "\n",
    "\n",
    "* En este Notebook vamos a ver que es la Regularización y los 3 tipos de regularización más populares (LASSO, Ridge y ElasticNet), asi como un ejemplo de regularización para la regresión lineal.\n",
    "<span></span><br>\n",
    "    1. [Regularización](#M1)\n",
    "<span></span><br>\n",
    "    2. [Regulariazión L1 - LASSO](#M2)\n",
    "<span></span><br>\n",
    "    3. [Regulariazión L2 - Ridge](#M3)\n",
    "<span></span><br>\n",
    "    4. [Regularización ElasticNet](#M4)\n",
    "<span></span><br>\n",
    "    5. [¿Cuando y Qué tipo de regularización usar? - Resumen](#M5)\n",
    "<span></span><br>\n",
    "    6. [Ejemplo: Regresión lineal múltiple con las 3 regularizaciones](#M6)\n",
    "    \n",
    "    \n",
    "<hr>\n",
    "\n",
    "\n",
    "## <a name=\"M1\">1. Regularización</a>\n",
    "\n",
    "\n",
    "* ***La Regularización en el Deep | Machine Lerning es un método que permite a los Algoritmos de Aprendizaje construir modelos menos complejos con el fin de que estos generalizen mejor, reduciendo el sobreajuste (Overfitting) del modelo*** a los datos de entrenamiento.\n",
    "\n",
    "\n",
    "* Por lo general los modelos más simples tienden a generalizar mejor que los modelos complejos; ya que estos últimos tienden a sobreajustarse a los datos de entrenamiento, obteniendo medidas de calidad (MSE, MAE, etc.) muy buenas en los datos de entrenamiento pero no tan buenas para los datos de test. Con modelos más simples somos capaces de obtener un equilibrio mayor de las medidas de calidad de los modelos entre los datos de entrenamiento y test.\n",
    "\n",
    "\n",
    "* Para el caso de la ***regresión lineal*** lo que se pretende es ***encontrar un modelo de la forma $h(x) = \\beta_0 + X_1 \\cdot \\beta_1 + ... + X_n \\cdot \\beta_n$***, obteniendo los mejores parámetros $\\beta_j$ que mejor se ajusten a los datos de entrenamiento y esto lo conseguimos ***minimizando la función de perdida (J)*** con el Error Cuadrático Medio (MSE).\n",
    "<span></span><br><br>\n",
    "<span style=\"font-size:16px\">$$J(\\beta) = MSE = \\frac{1}{N} \\sum_{i=1}^{N} (h(x^{(i)}) - y^{(i)})^2$$</span>\n",
    "\n",
    "\n",
    "* Lo que hacen los diferentes ***métodos de Regularización es penalizar la complejidad del modelos***, añadiendo a la función de perdida un nuevo término **'C'** que nos ***indicará la complejidad del modelo*** y este estará ***regulado por un hiperparámetro '$\\lambda$' que indicará el peso que le damos al termino de complejidad***, quedando la función de perdida que queremos minimizar de la siguiente manera:\n",
    "<span></span><br><br> \n",
    "<span style=\"font-size:16px\">$$J(\\beta) = MSE - \\lambda \\; C$$</span>\n",
    "\n",
    "\n",
    "* En función de como definamos o midamos la complejidad, tendremos los distintos tipos de regularización, siendo los más comunes los siguientes métodos:\n",
    "\n",
    "    + L1 - LASSO\n",
    "    + L2 - Ridge\n",
    "    + ElasticNet\n",
    "\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "## <a name=\"M2\">2. Regulariazión L1 - LASSO</a>\n",
    "\n",
    "\n",
    "* La Regularización L1; tambien conocida como LASSO (Least Absolute Shrinkage ans Selection Operator), se denomina L1 por utilizar como ***termino de complejidad la norma L1 que es la suma del valor absoluto de los parámetros del modelo***:\n",
    "<span></span><br><br> \n",
    "<span style=\"font-size:16px\">$$C = L1 = \\left \\| \\beta\\right \\|_1 = \\sum  \\left | \\beta_j \\right |$$</span>\n",
    "\n",
    "\n",
    "* Haciendo uso de la Regularización L1 en la regresión lineal, la función de perdida a minimizar quedaría de la siguiente manera:\n",
    "<span></span><br><br>\n",
    "<span style=\"font-size:16px\">$$\\underset{\\beta}{min} \\: J(\\beta) = \\frac{1}{2N} \\sum_{i=1}^{N} (h(x) - y^{(i)})^2 + \\lambda \\; \\sum_{j=1}^{j}  \\left | \\beta_j \\right |$$</span>\n",
    "\n",
    "\n",
    "* La Regularización L1 debemos usarla cuando sospechemos que ***varias de las variables de entrada vayan a ser irrelevantes para el modelo***, ya que estas tenderán a tener valores muy cercanos a cero.\n",
    "\n",
    "\n",
    "* También debemos de usarlo cuando las ***variables no están muy correladas entre sí***.\n",
    "\n",
    "\n",
    "* La Regularización L1 se propuso con el objetivo de dotar a los modelos (en particular a las redes neuronales) de la capacidad de 'olvidar', de ahí que con este tipo de Regularización obtengamos modelos en los que los parámetros de variables muy relevantes tengan valores altos y los parámetros sobre variables irrelevantes o altamente correladas con otras variables, tengan valores cercanos a cero.\n",
    "\n",
    "\n",
    "* Cuando hay variables altamente correladas entre sí, la Regularización L1 tiende a seleccionar una de ellas de forma aleatoria y olvidar el resto, poniendo sus parámetros con valores muy cercanos a cero.\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "## <a name=\"M3\">3. Regulariazión L2 - Ridge</a>\n",
    "\n",
    "\n",
    "* La Regularización L2; tambien conocida como Rigde (Arista), se denomina L2 por utilizar como ***termino de complejidad la norma L2 al cuadrado de un vector (o norma euclidea), que es la suma de los valores al cuadrado de los parámetros del modelo***:\n",
    "<span></span><br><br> \n",
    "<span style=\"font-size:16px\">$$C = L2 = \\left \\| \\beta\\right \\|_2^2 = \\sum  \\beta_j^2$$</span>\n",
    "\n",
    "\n",
    "* Haciendo uso de la Regularización L2 en la regresión lineal, la función de perdida a minimizar quedaría de la siguiente manera:\n",
    "<span></span><br><br>\n",
    "<span style=\"font-size:16px\">$$\\underset{\\beta}{min} \\: J(\\beta) = \\frac{1}{2N} \\sum_{i=1}^{N} (h(x) - y^{(i)})^2 + \\lambda \\; \\sum_{j=1}^{j}  \\beta_j^2$$</span>\n",
    "    \n",
    "\n",
    "* La Regularización L2 debemos usarla cuando en nuestro Dataset:\n",
    "    + ***La mayoría de las variables sean relevantes***.\n",
    "    + ***Las variables estén bastante correladas entre sí***. \n",
    "\n",
    "\n",
    "* La Regularización L2, penaliza fuertemente los valores de parámetros grandes y favorece la obtención de parámetros con valores pequeños, lo que hace que se minimice el efecto de la correlación entre las variables.\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "## <a name=\"M4\">4. Regularización ElasticNet</a>\n",
    "\n",
    "\n",
    "* La Regularización ElasticNet (Redes Elásticas) combina la Regularización L1 con la Regularización L2, calculando la ***complejidad del modelo como la suma de las complejidades dadas por la regularización L1 y L2***:\n",
    "<span></span><br><br>\n",
    "<span style=\"font-size:16px\">$$C = L1 + L2 = \\left \\| \\beta\\right \\|_1 + \\left \\| \\beta\\right \\|_2^2 = \\sum \\left | \\beta_j \\right | + \\sum  \\beta_j^2$$</span>\n",
    "\n",
    "\n",
    "* Por lo general en la Regularización ElasticNet se aplica un ***factor de importancia relativa 'r'*** para dar (si se quiere) más peso a la Regularización L1 que a la L2 o viceversa:\n",
    "<span></span><br><br>\n",
    "<span style=\"font-size:16px\">$$C = r \\; L1 + (1-r) \\; L2 $$</span>\n",
    "\n",
    "\n",
    "* Haciendo uso de la Regularización ElasticNet en la regresión lineal, la función de perdida a minimizar quedaría de la siguiente manera:\n",
    "<span></span><br><br>\n",
    "    <span style=\"font-size:16px\">$$\\underset{\\beta}{min} \\: J(\\beta) = \\frac{1}{2N} \\sum_{i=1}^{N} (h(x) - y^{(i)})^2 + \\lambda \\; r \\;\\sum_{j=1}^{j}  \\left | \\beta_j \\right | + \\lambda \\; (1-r) \\; \\sum_{j=1}^{j}  \\beta_j^2$$</span>\n",
    "\n",
    "\n",
    "* La Regularización ElasticNet debemos usarla cuando en nuestro ***Dataset tengamos un gran número de variables y cuando se cumplas las características descritas para ambas regularizaciones L1 y L2***, que son:\n",
    "    + ***Varias de las variables de entrada vayan a ser irrelevantes***.\n",
    "    + ***Las variables estén bastante correladas entre sí***.\n",
    "    \n",
    "<hr>\n",
    "\n",
    "\n",
    "## <a name=\"M5\">5. ¿Cuando y Qué tipo de regularización usar? - Resumen</a>\n",
    "\n",
    "### ¿Cuando hay que usar Regularización?\n",
    "\n",
    "\n",
    "* La Regularización es un método que no resulta necesario aplicar cuando trabajamos en el ajuste de modelos \"simples\" con pocos parámetros; sin embargo, resulta imprescindible ***aplicarlo cuando se trata de ajustar un modelo muy complejo en el que hay cientos o miles de parámetros***.\n",
    "\n",
    "\n",
    "### ¿Qué tipo de regularización usar? - Resumen\n",
    "\n",
    "\n",
    "#### - L1 - LASSO\n",
    "\n",
    "\n",
    "* ***Varias de las variables de entrada vayan a ser irrelevantes para el modelo***\n",
    "\n",
    "\n",
    "* ***Las variables del Dataset no están muy correladas entre sí***.\n",
    "\n",
    "\n",
    "#### - L2 -Ridge\n",
    "\n",
    "\n",
    "* ***La mayoría de las variables del Dataset sean relevantes***.\n",
    "\n",
    "\n",
    "* ***Las variables del Dataset estén bastante correladas entre sí***. \n",
    "\n",
    "\n",
    "#### - ElasticNet\n",
    "\n",
    "\n",
    "* ***En nuestro Dataset tengamos un gran número de variables***.\n",
    "\n",
    "\n",
    "* ***Varias de las variables de entrada vayan a ser irrelevantes***.\n",
    "\n",
    "\n",
    "* ***Las variables del Dataset estén bastante correladas entre sí***.\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "## <a name=\"M6\">6. Ejemplo: Regresión lineal múltiple con las 3 regularizaciones</a>\n",
    "\n",
    "\n",
    "* A continuación vamos a resolver un problema de regresión lineal múltiple en el que vamos a aplicar las 3 regularizaciones vistas anteriormente y compararlas entre sí junto con una regresión lineal múltiple sin regularizar.\n",
    "\n",
    "\n",
    "* En los siguientes puntos se muestran los enlaces a la documentación de Scikit para cada una de las regresiones a utilizar:\n",
    "\n",
    "    + ***LinearRegression***: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "    + ***Lasso***: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "    + ***Ridge***: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "    + ***ElasticNet***: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "\n",
    "\n",
    "* El objetivo de este ejemplo es ver que modelos nos devuelven cada una de las regresiones propuestas para ver sus diferencias y evaluar estos modelos con los conjuntos de datos de entrenamiento y test para ver si obtenemos resultados diferentes entre ellos.\n",
    "\n",
    "\n",
    "* El problema de regresión que vamos a resolver es el de predecir cuantas ***calorías quema una persona en función de los minutos que corre, la velocidad a la que corre y su peso corporal***. Por ello tenemos un conjunto de datos tomados de forma empírica que nos dan esa relación. \n",
    "\n",
    "\n",
    "* El objetivo es encontrar los parámetros $\\beta_0, \\beta_1, \\beta_2, \\beta_3$ que mejor se ajustan a esos datos.\n",
    "\n",
    "    <span style=\"font-size:16px\">$$Calorias = \\beta_0 + \\beta_1 \\cdot Tiempo + \\beta_2 \\cdot Velocidad + \\beta_3 \\cdot Peso$$</span>\n",
    "    \n",
    "    \n",
    "* Para hacer algo más didáctico el ejemplo y poder ver las diferencias entre las 4 regresiones a realizar, vamos a crearnos una nueva variable que será \"Velocidad_Millas\" que será la velocidad en millas por hora y que estará 100% correlada con la variable \"Velocidad\". De esta manera podremos ver mejor las diferencias entre las diferentes regresiones.\n",
    "\n",
    "\n",
    "* Para realizar este ejercicio realizaremos los siguientes pasos:\n",
    "    1. Carga de datos y creacción de la variable \"Velocidad_Millas\"\n",
    "    2. Cálculo de correlación entre variables\n",
    "    3. Paso de los Datos a Numpy División de datos en entrenamiento y test (20%)\n",
    "    4. Ajuste de los modelos\n",
    "    5. Obtención de los modelos y diferencias\n",
    "    6. Evaluación de los modelos\n",
    "    \n",
    "    \n",
    "* En primer lugar vamos a importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "### 1. Carga de datos y creacción de la variable \"Velocidad_Millas\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Calorias</th>\n",
       "      <th>Tiempo</th>\n",
       "      <th>Peso</th>\n",
       "      <th>Velocidad</th>\n",
       "      <th>Velocidad_Millas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>769.3</td>\n",
       "      <td>44.8</td>\n",
       "      <td>77.5</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>257.3</td>\n",
       "      <td>20.5</td>\n",
       "      <td>63.1</td>\n",
       "      <td>11.5</td>\n",
       "      <td>7.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2972</td>\n",
       "      <td>517.5</td>\n",
       "      <td>32.7</td>\n",
       "      <td>71.5</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4953</td>\n",
       "      <td>480.5</td>\n",
       "      <td>26.3</td>\n",
       "      <td>71.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>9.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3725</td>\n",
       "      <td>600.0</td>\n",
       "      <td>69.3</td>\n",
       "      <td>55.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Calorias  Tiempo  Peso  Velocidad  Velocidad_Millas\n",
       "223      769.3    44.8  77.5       12.8             7.936\n",
       "80       257.3    20.5  63.1       11.5             7.130\n",
       "2972     517.5    32.7  71.5       12.8             7.936\n",
       "4953     480.5    26.3  71.0       14.9             9.238\n",
       "3725     600.0    69.3  55.4        9.0             5.580"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/calorias_running/calories_time_weight_speed.csv\")\n",
    "df['Velocidad_Millas'] = df['Velocidad'].apply(lambda x: x * 0.62)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "### 2. Cálculo de correlación entre variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1da34250>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_corr = df.corr().abs()\n",
    "df_upper = df_corr.where(np.triu(np.ones(df_corr.shape), k=1).astype(np.bool))\n",
    "sns.heatmap(df_upper, annot=True, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "### 3. Paso de los Datos a Numpy División de datos en entrenamiento y test (20%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos un 20% de datos de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Tiempo' ,'Peso', 'Velocidad', 'Velocidad_Millas']].values, \n",
    "                                                    df['Calorias'].values, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "### 4. Ajuste de los modelos\n",
    "\n",
    "\n",
    "* A continuación vamos a crear los objetos de los diferentes Algoritmos de Aprendizaje y posteriormente ajustaremos los modelos con los datos de entrenamiento.\n",
    "\n",
    "\n",
    "* A los Algoritmos de Aprendizaje que implementan regularización, tienen el parámetros 'alpha' que es el 'hiperparámetro lambda' visto anteriormente, usado para indicar el peso que se le da al termino de complejidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "reg_l1 = linear_model.Lasso(alpha=1)\n",
    "reg_l2 = linear_model.Ridge(alpha=1)\n",
    "reg_en = linear_model.ElasticNet(alpha=1)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "reg_l1.fit(X_train, y_train)\n",
    "reg_l2.fit(X_train, y_train)\n",
    "reg_en.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "### 5. Obtención de los modelos y diferencias\n",
    "\n",
    "\n",
    "* Con el problema propuesto en el que tenemos una variable correlada al 100% con otra, podemos deducir los siguientes supuestos:\n",
    "\n",
    "    1. El modelo dará una importancia similar a las dos variables correlacionadas sin minimizando la complejidad del modelo.\n",
    "    2. El modelo dará una importancia similar a las dos variables correlacionadas minimizando la complejidad del modelo.\n",
    "    3. El modelo dará importancia a una de las dos variables correlacionadas y a la otra no le dará importancia.\n",
    "    \n",
    "    \n",
    "* Con los modelos obtenidos podemos concluir lo siguiente:\n",
    "\n",
    "1.- ***Regresión Lineal***: Obtiene un modelo \"muy complejo\" con unos parámetros con valores muy altos (sobre todo con los asociados a las variables de la velocidad) y dando una importancia relevante a los parámetros de las variables correlacionadas.\n",
    "\n",
    "Y = -1162.67 + 14.26 Tiempo + 8.55 Peso + 2232060626818.63 Velocidad + -3600097785116.20 Velocidad_Millas\n",
    "    \n",
    "2.- ***LASSO Regression***: Obtiene un modelo en el que considera una de las variables correlacionadas irrelevante, por lo que a una le da todo el peso de la importancia y a la otra le da un peso de 0.\n",
    "\n",
    "Y = -1158.06 + 14.25 Tiempo + 8.54 Peso + 46.31 Velocidad + 0.00 Velocidad_Millas\n",
    "\n",
    "3.- ***Ridge Regression***: Obtiene un modelo en el que distribuye el peso de la importancia entre las dos variables correlacionadas entre sí.\n",
    "\n",
    "Y = -1162.64 + 14.26 Tiempo + 8.55 Peso + 33.65 Velocidad + 20.86 Velocidad_Millas\n",
    "\n",
    "4.- ***ElasticNet Regression***: Obtiene un modelo en el que distribuye el peso de la importancia entre las dos variables correlacionadas entre sí, pero en este caso da algo más de importancia a una variable que a otra en comparación con el modelo obtenido con la \"Rigde Regression\".\n",
    "\n",
    "Y = -1099.09 + 14.12 Tiempo + 8.48 Peso + 30.73 Velocidad + 18.66 Velocidad_Millas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo Regresión Lineal - Sin Regularización:\n",
      "Y = -1162.67 + 14.26 Tiempo + 8.55 Peso + 2232060626818.63 Velocidad + -3600097785116.20 Velocidad_Millas\n",
      "\n",
      "Modelo Regresión Lineal - Regularización L1:\n",
      "Y = -1158.06 + 14.25 Tiempo + 8.54 Peso + 46.31 Velocidad + 0.00 Velocidad_Millas\n",
      "\n",
      "Modelo Regresión Lineal - Regularización L2:\n",
      "Y = -1162.64 + 14.26 Tiempo + 8.55 Peso + 33.65 Velocidad + 20.86 Velocidad_Millas\n",
      "\n",
      "Modelo Regresión Lineal - Regularización ElasticNet:\n",
      "Y = -1099.09 + 14.12 Tiempo + 8.48 Peso + 30.73 Velocidad + 18.66 Velocidad_Millas\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModelo Regresión Lineal - Sin Regularización:\")\n",
    "betas = reg.coef_\n",
    "beta_0 = reg.intercept_\n",
    "print (\"Y = {b0:0.2f} + {b1:0.2f} Tiempo + {b2:0.2f} Peso + {b3:0.2f} Velocidad + {b4:0.2f} Velocidad_Millas\"\n",
    "       .format(b0=beta_0, b1=betas[0], b2=betas[1], b3=betas[2], b4=betas[3]))\n",
    "\n",
    "print(\"\\nModelo Regresión Lineal - Regularización L1:\")\n",
    "betas = reg_l1.coef_\n",
    "beta_0 = reg_l1.intercept_\n",
    "print (\"Y = {b0:0.2f} + {b1:0.2f} Tiempo + {b2:0.2f} Peso + {b3:0.2f} Velocidad + {b4:0.2f} Velocidad_Millas\"\n",
    "       .format(b0=beta_0, b1=betas[0], b2=betas[1], b3=betas[2], b4=betas[3]))\n",
    "\n",
    "print(\"\\nModelo Regresión Lineal - Regularización L2:\")\n",
    "betas = reg_l2.coef_\n",
    "beta_0 = reg_l2.intercept_\n",
    "print (\"Y = {b0:0.2f} + {b1:0.2f} Tiempo + {b2:0.2f} Peso + {b3:0.2f} Velocidad + {b4:0.2f} Velocidad_Millas\"\n",
    "       .format(b0=beta_0, b1=betas[0], b2=betas[1], b3=betas[2], b4=betas[3]))\n",
    "\n",
    "print(\"\\nModelo Regresión Lineal - Regularización ElasticNet:\")\n",
    "betas = reg_en.coef_\n",
    "beta_0 = reg_en.intercept_\n",
    "print (\"Y = {b0:0.2f} + {b1:0.2f} Tiempo + {b2:0.2f} Peso + {b3:0.2f} Velocidad + {b4:0.2f} Velocidad_Millas\"\n",
    "       .format(b0=beta_0, b1=betas[0], b2=betas[1], b3=betas[2], b4=betas[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "### 6. Evaluación de los modelos\n",
    "\n",
    "\n",
    "* Con los resultados obtenidos en la evaluación de los diferentes modelos, no se aprecian diferencias importantes entre los diferentes. Esto es debido a que el modelo generado lo podemos considerar como un modelo \"simple\" ya que tiene solo 5 parámetros ($\\beta_0, ..., \\beta_4$) con lo que todos los Algoritmos de Aprendizaje aplicados generan modelos muy buenos que se ajustan muy bien a los datos de entrenamiento y test; por lo tanto, son modelos que generalizan muy bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Regresión Lineal</td>\n",
       "      <td>47.395787</td>\n",
       "      <td>51.082573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LASSO - L1</td>\n",
       "      <td>47.381194</td>\n",
       "      <td>51.092122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ridge - L2</td>\n",
       "      <td>47.390980</td>\n",
       "      <td>51.079419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>47.778695</td>\n",
       "      <td>51.738050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train       test\n",
       "name                                  \n",
       "Regresión Lineal  47.395787  51.082573\n",
       "LASSO - L1        47.381194  51.092122\n",
       "Ridge - L2        47.390980  51.079419\n",
       "ElasticNet        47.778695  51.738050"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {'Regresión Lineal': reg,\n",
    "          'LASSO - L1': reg_l1,\n",
    "          'Ridge - L2': reg_l2,\n",
    "          'ElasticNet': reg_en}\n",
    "maes = list()\n",
    "for key, model in models.items():\n",
    "    mae = dict()\n",
    "    mae['name'] = key\n",
    "    y_train_predict = model.predict(X_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    mae['train'] = mean_absolute_error(y_true=y_train, y_pred=y_train_predict)\n",
    "    mae['test'] = mean_absolute_error(y_true=y_test, y_pred=y_test_predict)\n",
    "    maes.append(mae)\n",
    "\n",
    "# Pasamos los resultados a un DataFrame para visualizarlos mejor\n",
    "df = pd.DataFrame.from_dict(maes)\n",
    "df.set_index(\"name\", inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "Este Notebook ha sido desarrollado por **Ricardo Moya García** y registrado en Safe Creative como ***Atribución-NoComercial-CompartirIgual***.\n",
    "\n",
    "\n",
    "<img src=\"../../imgs/CC_BY-NC-SA.png\" alt=\"CC BY-NC\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 - Tecnicas de Evaluacion\n",
    "\n",
    "\n",
    "* En este Notebook vamos a ver ***4 técnicas de evaluación***; es decir, de que manera se pueden dividir los datasets en conjuntos de datos de entrenamiento y test y como se ***implementaría*** esta división de datos con la librería de ***Scikit-Learn***.\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "* Para evaluar los modelos obtenidos tras la aplicación de alguna de las técnicas de ML, es necesario disponer de un ***conjunto de datos*** (etiquetados o no) para ***generar el mejor modelo  posible y minimizar el error empírico***.\n",
    "\n",
    "\n",
    "* Dado un conjunto de datos, podemos enumerar los siguientes ***métodos de evaluación*** en función de cómo se dividen los datos de entrenamiento y de test:\n",
    "<span></span><br><br>\n",
    "    - **[Resustitución](#M0)**: Todos los datos disponibles se utilizan como datos de test y de entrenamiento.\n",
    "<span></span><br><br>\n",
    "    - **[Partición (Hold Out)](#M1)**: Divide los datos en dos subconjuntos: uno de entrenamiento y uno de test.\n",
    "<span></span><br><br>\n",
    "    - **[Validación cruzada (Cross Validation)](#M2)**: Divide los datos aleatoriamente en ‘N’ bloques. Cada bloque se utiliza como test para un sistema entrenado por el resto de bloques.\n",
    "<span></span><br><br>\n",
    "    - **[Exclusión individual (Leave One Out)](#M3)**: Este método utiliza cada dato individual como dato único de test de un sistema entrenado con todos los datos excepto el de test.\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "\n",
    "## Ejemplos\n",
    "\n",
    "\n",
    "* Para ver ejemplos de estas técnicas de evaluación supongamos el siguiente conjunto de datos donde:\n",
    "<span></span><br><br>\n",
    "    - ***(i)***: índice del conjunto de datos.\n",
    "    - ***X<sub>1</sub> y X<sub>2</sub>***: Variables de entrada.\n",
    "    - ***y***: Variable de salida.\n",
    "\n",
    "\n",
    "|(i)|X<sub>1</sub>|X<sub>2</sub>|y|\n",
    "|---|---|---|---|\n",
    "|1|0|1|1|\n",
    "|2|1|1|4|\n",
    "|3|1|2|6|\n",
    "|4|2|1|7|\n",
    "|5|2|2|9|\n",
    "|6|3|1|10|\n",
    "|7|3|2|12|\n",
    "|8|3|3|14|\n",
    "|9|1|3|8|\n",
    "|10|2|3|11|\n",
    "\n",
    "\n",
    "* En este ejemplo vamos a tener ***10 elementos*** en nuestro conjundo de datos y los vamos a pasar a un ***array de numpy***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,1],[1,1],[1,2],[2,1],[2,2],[3,1],[3,2],[3,3],[1,3],[2,3]])\n",
    "y = np.array([1,4,6,7,9,10,12,14,8,11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "\n",
    "## <a name=\"M0\">1. Resustitución</a>\n",
    "\n",
    "\n",
    "* Para el caso de la resustitución es muy sencilla; ***todos los datos del Dataset sirven para el Entrenamiento y el Test***.\n",
    "\n",
    "\n",
    "* A modo didactico realizamos la siguiente asignación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "# modelo = Algoritmo_de_Aprendizaje.entrenar(X_train, y_train)\n",
    "\n",
    "X_test = X\n",
    "y_test = y\n",
    "\n",
    "# evaluar_modelo = modelo.evaluar(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "\n",
    "## <a name=\"M1\">2. Hold Out</a>\n",
    "\n",
    "\n",
    "* La técnica de evaluación ***Hold Out*** divide el Dataset en un ***conjunto de datos de entrenamiento*** y otro ***conjunto de datos de test***, seleccionados a priori de manera aleatoria.\n",
    "\n",
    "\n",
    "<img src=\"../imgs/2_01_01_tec_eval.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "* En Scikit utilizamos la función ***train_test_split(X,y,test_size)*** para que nos divida en dos conjuntos el Dataset, indicando como parámetro el porcentaje de datos de test que quermos obtener:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Seleccionamos un 20% de datos de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# modelo = Algoritmo_de_Aprendizaje.entrenar(X_train, y_train)\n",
    "\n",
    "# evaluar_modelo = modelo.evaluar(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2],\n",
       "       [2, 1],\n",
       "       [1, 3],\n",
       "       [3, 3],\n",
       "       [2, 3],\n",
       "       [1, 2],\n",
       "       [2, 2],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  7,  8, 14, 11,  6,  9,  4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [3, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## <a name=\"M2\">3. Cross Validation</a>\n",
    "\n",
    "\n",
    "* La técnica del ***Cross Validatión, divide el Dataset en 'N' conjuntos*** (o Folds como Scikit lo llama).\n",
    "\n",
    "\n",
    "* Para cada uno de los ***'N'*** casos se utiliza un conjunto como datos de test y el resto de conjuntos como datos de entrenamiento.\n",
    "\n",
    "\n",
    "* Esta técnica tiene sentido aplicarla cuando se quiere evaluar el modelo generado ***'N'*** veces.\n",
    "\n",
    "\n",
    "<img src=\"../imgs/2_01_02_tec_eval.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "* En Scikit utilizamos la clase ***KFold(n_splits)*** para dividir el Dataset en ***'N'*** (n_splits) conjuntos.\n",
    "\n",
    "\n",
    "* En este caso no vamos a obtener unos arrays con los datos de entrenamiento y test; si no, los ***índices de los elementos del Dataset que en cada paso actuarán como entrenamiento y como test***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Índices Train  -  Índices Test\n",
      "[2 3 4 5 6 7 8 9] - [0 1]\n",
      "[0 1 4 5 6 7 8 9] - [2 3]\n",
      "[0 1 2 3 6 7 8 9] - [4 5]\n",
      "[0 1 2 3 4 5 8 9] - [6 7]\n",
      "[0 1 2 3 4 5 6 7] - [8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Dividimos el Dataset en 5 conjuntos de datos\n",
    "k_fold = KFold(n_splits=5)\n",
    "\n",
    "# Obtengo los índices de train y test para cada uno de los conjuntos\n",
    "print(\"   Índices Train  -  Índices Test\")\n",
    "for train, test in k_fold.split(X,y):\n",
    "    print(\"{} - {}\".format(train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Si se quiere ***acceder a los datos*** que es lo que interesa se tienen que pasar los índices a los numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: [ 6  7  9 10 12 14  8 11]\n",
      "y_test: [1 4]\n",
      "\n",
      "y_train: [ 1  4  9 10 12 14  8 11]\n",
      "y_test: [6 7]\n",
      "\n",
      "y_train: [ 1  4  6  7 12 14  8 11]\n",
      "y_test: [ 9 10]\n",
      "\n",
      "y_train: [ 1  4  6  7  9 10  8 11]\n",
      "y_test: [12 14]\n",
      "\n",
      "y_train: [ 1  4  6  7  9 10 12 14]\n",
      "y_test: [ 8 11]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Dividimos el Dataset en 5 conjuntos de datos\n",
    "k_fold = KFold(n_splits=5)\n",
    "\n",
    "# Ejemplo de como accedemos a los elementos de la variable de salida y\n",
    "for train, test in k_fold.split(X,y):\n",
    "    \n",
    "    print('y_train: {}'.format(y[train]))\n",
    "    # modelo = Algoritmo_de_Aprendizaje.entrenar(X[train], y[train])\n",
    "\n",
    "    print('y_test: {}\\n'.format(y[test]))\n",
    "    # evaluar_modelo = modelo.evaluar(X[test], y[test])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## <a name=\"M3\">4. Leave One Out</a>\n",
    "\n",
    "\n",
    "* La técnica del ***Leave One One*** es una técnica similar al Cross Validation, pero en este caso el Dataset se ***divide en tantos conjuntos como elementos tenga el Dataset***.\n",
    "\n",
    "\n",
    "* Para cada uno de los ***'M'*** elemetos se utiliza un elemento como dato de test y el resto de elementos como datos de entrenamiento.\n",
    "\n",
    "\n",
    "* Esta ***técnica es muy costosa de aplicar*** ya que se van a tener tantas iteracciones como elementos tenga el Dataset (***'M'*** veces).\n",
    "\n",
    "\n",
    "* Puede tener sentido aplicar esta técnica cuando se tenga un Dataset pequeño y necesitemos evaluar muy a fondo el modelo.\n",
    "\n",
    "\n",
    "<img src=\"../imgs/2_01_03_tec_eval.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "* En Scikit utilizamos la clase ***LeaveOneOut()*** para dividir el Dataseten tantos conjuntos como elementos tenga.\n",
    "\n",
    "\n",
    "* En este caso no vamos a obtener unos arrays con los datos de entrenamiento y test; si no, los ***índices de los elementos del Dataset que en cada paso actuarán como entrenamiento y como test***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Índices Train   -  Índices Test\n",
      "[1 2 3 4 5 6 7 8 9] - [0]\n",
      "[0 2 3 4 5 6 7 8 9] - [1]\n",
      "[0 1 3 4 5 6 7 8 9] - [2]\n",
      "[0 1 2 4 5 6 7 8 9] - [3]\n",
      "[0 1 2 3 5 6 7 8 9] - [4]\n",
      "[0 1 2 3 4 6 7 8 9] - [5]\n",
      "[0 1 2 3 4 5 7 8 9] - [6]\n",
      "[0 1 2 3 4 5 6 8 9] - [7]\n",
      "[0 1 2 3 4 5 6 7 9] - [8]\n",
      "[0 1 2 3 4 5 6 7 8] - [9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "print(\"    Índices Train   -  Índices Test\")\n",
    "for train, test in loo.split(X):\n",
    "    print(\"{} - {}\".format(train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Si se quiere ***acceder a los datos*** que es lo que interesa se tienen que pasar los índices a los numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: [ 4  6  7  9 10 12 14  8 11]\n",
      "y_test: [1]\n",
      "\n",
      "y_train: [ 1  6  7  9 10 12 14  8 11]\n",
      "y_test: [4]\n",
      "\n",
      "y_train: [ 1  4  7  9 10 12 14  8 11]\n",
      "y_test: [6]\n",
      "\n",
      "y_train: [ 1  4  6  9 10 12 14  8 11]\n",
      "y_test: [7]\n",
      "\n",
      "y_train: [ 1  4  6  7 10 12 14  8 11]\n",
      "y_test: [9]\n",
      "\n",
      "y_train: [ 1  4  6  7  9 12 14  8 11]\n",
      "y_test: [10]\n",
      "\n",
      "y_train: [ 1  4  6  7  9 10 14  8 11]\n",
      "y_test: [12]\n",
      "\n",
      "y_train: [ 1  4  6  7  9 10 12  8 11]\n",
      "y_test: [14]\n",
      "\n",
      "y_train: [ 1  4  6  7  9 10 12 14 11]\n",
      "y_test: [8]\n",
      "\n",
      "y_train: [ 1  4  6  7  9 10 12 14  8]\n",
      "y_test: [11]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Ejemplo de como accedemos a los elementos de la variable de salida y\n",
    "for train, test in loo.split(X,y):\n",
    "\n",
    "    print('y_train: {}'.format(y[train]))\n",
    "    # modelo = Algoritmo_de_Aprendizaje.entrenar(X[train], y[train])\n",
    "\n",
    "    print('y_test: {}\\n'.format(y[test]))\n",
    "    # evaluar_modelo = modelo.evaluar(X[test], y[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "Este Notebook ha sido desarrollado por **Ricardo Moya García** y registrado en Safe Creative como ***Atribución-NoComercial-CompartirIgual***.\n",
    "\n",
    "\n",
    "<img src=\"../imgs/CC_BY-NC-SA.png\" alt=\"CC BY-NC\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

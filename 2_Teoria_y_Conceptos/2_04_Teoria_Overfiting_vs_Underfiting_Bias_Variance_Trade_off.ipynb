{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4- Overfiting vs Underfiting & Bias-Variance: Trade-Off\n",
    "\n",
    "\n",
    "* En este Notebook vamos a ver los conceptos de:\n",
    "<span></span><br>\n",
    "    1. [Overfiting vs Underfiting](#M1)\n",
    "<span></span><br>\n",
    "    2. [Bias-Variance: Trade-Off](#M2)\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <a name=\"M1\">1. Overfiting vs Underfiting</a>\n",
    "\n",
    "\n",
    "* Uno de los objetivos que se tiene que perseguir a la hora de generar un modelo es que este sea capaz de predecir correctamente nuevos elementos que nunca ha visto; es decir, con el mínimo error posible.\n",
    "\n",
    "\n",
    "* A la hora de generar un modelo, tenemos que:\n",
    "<span></span><br><br>\n",
    "    1. ***Utilizar un Algoritmo de Aprendizaje*** al cual le ***indicaremos*** de una manera u otra (dependiendo del Algoritmo de Aprendizaje) ***la complejidad*** del modelo.\n",
    "<span></span><br><br>\n",
    "    2. Pasar al Algoritmo de Aprendizaje un ***conjunto de datos de entrenamiento*** lo suficientemente grande y variado para que genere un buen modelo.\n",
    "<span></span><br><br>\n",
    "    3. ***Evaluar con un conjunto de datos de test***, si el modelo generado comete unos errores similares a los que se comenten con el conjunto de datos de entrenamiento. De esa manera podremos concluir que un modelo generaliza correctamente ya que predice de igual manera elementos ya conocidos y elementos que nunca ha visto.\n",
    "    \n",
    "    \n",
    "* De esta manera podemos decir que:\n",
    "<span></span><br><br>\n",
    "    + ***Underfitting*** (sobregeneralización) se da cuando el modelo generado comete errores bastante altos tanto con los datos de entrenamiento como con los datos de test.\n",
    "<span></span><br><br>\n",
    "    + ***Overfitting*** (sobreajuste) se da cuando el modelo generado comete errores muy pequeños con los datos de entrenamiento y errores muy grandes con los datos de test.\n",
    "<span></span><br><br>\n",
    "    + ***Ajuste Correcto*** se da cuando el modelo generado comete errores similares tanto con los datos de entrenamiento como con los datos de test.\n",
    "\n",
    "<span></span><br>\n",
    "* Veamos a continuación 2 ejemplos de overfitting, underfitting y un ajuste correcto para los problemas de Clasificación y Regresión:\n",
    "<span></span><br><br>\n",
    "    + ***Clasificación***:\n",
    "<span></span><br><br>\n",
    "<img src=\"../imgs/2_04_01_th.png\" style=\"width: 700px;\"/>\n",
    "<span></span><br><br>\n",
    "    + ***Regresión***:\n",
    "<span></span><br><br>\n",
    "<img src=\"../imgs/2_04_02_th.png\" style=\"width: 700px;\"/>\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "## <a name=\"M2\">2. Bias-Variance: Trade-Off</a>\n",
    "\n",
    "\n",
    "* Aunque vamos ir desarrollando estos conceptos, podemos definir de primeras el Bias y Variance de la siguiente manera:\n",
    "<span></span><br><br>\n",
    "    + ***Bias***: Error obtenido por el conjunto de datos de entrenamiento.\n",
    "<span></span><br><br>\n",
    "    + ***Variance***: Error obtenido por el conjunto de datos de test.\n",
    "\n",
    "\n",
    "* Cuando generamos un modelo $f(x)$, este lo tenemos que evaluar con alguna métrica de evaluación como puede ser por ejemplo; para el caso de un problema de regresión, el error cuadrático medio (MSE) que lo definimo como:\n",
    "<span></span><br><br> \n",
    "\n",
    "$$MSE(x) = (f(x) - y)^2$$\n",
    "\n",
    "\n",
    "* Este error se puede descomponer en 3 tipos de errores que son:\n",
    "<span></span><br><br>\n",
    "    + ***Bias*** (sesgo): Mide la desviación entre las predicciones de nuestro modelo y los valores reales que tenemos que predecir. \n",
    "<span></span><br><br>\n",
    "    + ***Variance*** (varianza): Mide la variabilidad del modelo obtenido en función de los datos concretos utilizados en cada momento; es decir, si contruimos varios modelos del mismo tipo usando diferentes conjuntos de entrenamiento, la varianza representa cuanto varian las predicciones de los distintos modelos cuando los utilicemos para realizar una predicción concreta sobre un caso de prueba.\n",
    "<span></span><br><br>\n",
    "    + ***Irreducible Error***: Error que no puede ser reducido independientemente del algoritmo de aprendizaje a utilizar. Este error puede venir dado por variables desconocidas que influyen en el resultado final de la predicción.\n",
    "<span></span><br><br>   \n",
    "* Quedando descompuesto el error de la siguiente manera:\n",
    "<span></span><br><br> \n",
    "\n",
    "$$MSE(x) = Bias^{2}(x) + Variance(x) + Irreducible Error^2$$\n",
    "\n",
    "\n",
    "* Consideraremos el error irreducible como '$0$' quedando el error como:\n",
    "<span></span><br><br> \n",
    "\n",
    "$$MSE(x) = Bias^{2}(x) + Variance(x)$$\n",
    "\n",
    "\n",
    "* Uno de los puntos que tenemos que tener en cuenta cuando creamos un modelo con un algoritmo de aprendizaje es el de definir la complejidad que va a tener el modelo. Sobre la complejidad de los modelos podemos decir:\n",
    "<span></span><br><br>\n",
    "    + Los ***modelos que baja complejidad*** son modelos que generalizan mejor que los modelos de alta complejidad; sin embargo, pueden tener problemas de underfitting.\n",
    "<span></span><br><br>    \n",
    "    + Los ***modelos de alta complejidad*** son modelos que generalizan peor que los modelos de baja complejidad; sin embargo, pueden tener problemas de overfitting.\n",
    "    \n",
    "    \n",
    "* Para obtener el modelo de complejidad \"óptima\" tenemos que estudiar los errores cometidos en función de el error obtenido con los datos de entrenamiento y el error obtenido con los datos de test y encontrar un equilibrio entre esos errores.\n",
    "\n",
    "\n",
    "* En la siguiente imagen podemos ver un ejemplo del error cometido con los datos de entrenamiento y con los datos de test en función de la complejidad del modelo:\n",
    "\n",
    "\n",
    "<img src=\"../imgs/2_04_03_th.png\" style=\"width: 800px;\"/>\n",
    "\n",
    "\n",
    "* Viendo la imagen podemos apreciar los siguiente:\n",
    "<span></span><br><br>  \n",
    "    1. Si el ***modelo tiene una complejidad baja***, el ***error*** cometido tanto con los ***datos de entrenamiento*** como los de ***test*** es ***alto*** con lo que nuestro modelo sufrirá de ***underfitting*** y tendra un ***alto bias*** (high bias).\n",
    "<span></span><br><br>  \n",
    "    2. Si el ***modelo tiene una complejidad alta*** (o excesiva) este se ajustará muy bien a los datos de entrenamiento y sufrirá de ***overfitting*** miestras que se ***ajustará mal a los datos de test*** obteniendo un error muy alto con los datos de test lo que significará que tiene una ***varianza muy alta***.\n",
    "<span></span><br><br> \n",
    "    3. Se puede observar que con un ***modelo de complejidad media*** (óptima) los ***errores*** cometidos con los datos de ***entrenamiento y test son similares*** por tanto tendrán un ***bajo bias y una baja varianza***.\n",
    "    \n",
    "    \n",
    "En la siguiente imagen podemos ver los diferentes errores descompuestos en función de la complejidad del modelo y un resumen de lo explicado en los 3 puntos anteriores.\n",
    "\n",
    "<img src=\"../imgs/2_04_04_th.png\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "Este Notebook ha sido desarrollado por **Ricardo Moya García** y registrado en Safe Creative como ***Atribución-NoComercial-CompartirIgual***.\n",
    "\n",
    "\n",
    "<img src=\"../imgs/CC_BY-NC-SA.png\" alt=\"CC BY-NC\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
